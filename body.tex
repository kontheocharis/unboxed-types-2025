When the reduction rules of type theory become part of its static semantics, it
is sometimes impossible to compute the memory size in bytes of a type during compilation.
This happens when polymorphism is present but monomorphisation is not, and in
particular when dependent types are part of the mix, since the dependency might
be on runtime values.

In this ongoing work, we formulate a dependent type theory where the memory size
of a type is always known at compile-time, and thus compilation can directly
target a low-level language. Boxing is opt-in and
can be avoided, leading to efficient code that enables cache locality. This is
done by \emph{indexing} syntactic types by a metatheoretic type describing
memory layouts: $\Bytes$. This leads to a notion of representation polymorphism.
Unboxed data in functional languages has been explored before
\cite{Jones1991-ik,Eisenberg2017-pq,Downen2024-nk}, but results in overly restricted polymorphism
or complex theories with multiple levels of kinds separating values and
computations, and without support for full dependent types. Our approach is
lightweight and extends to dependent types.

The staging view of \emph{two-level type theory} (2LTT) \cite{Annenkov2023-vk}
has been explored by Kov\'acs in the general setting \cite{Kovacs2022-rf} as
well as in the setting of closure-free functional programming
\cite{Kovacs2024-hn}. Inspired by a note in the aforementioned works, we can embed
our unboxed type theory as the object language of a 2LTT, which allows us to
write type-safe metaprograms that compute representation-specific constructions.
For example, we can formulate a universe of flat protocol specifications in the
style of Allais \cite{Allais2023-zq}, and interpret it in the unboxed object
theory.
We needn't compromise on the usage of dependent types either; as opposed to
\cite{Kovacs2024-hn}, the object theory is itself dependently typed and thus we
can encode unboxed higher-order polymorphic functions as part of the final
program, because all \emph{sizes} (not necessarily all types) are known after staging.

\paragraph{Basic setup}
We formulate our system in the form of a second-order generalised
algebraic theory (SOGAT) \cite{Kaposi2024-db}.
We assume a metatheoretic type of
\(\Bytes\) with
\[
	0, 1 : \Bytes \qquad \qquad + : \Bytes \to \Bytes \to \Bytes \qquad \ptr : \Bytes \qquad \times : \syn{Nat} \to \Bytes \to \Bytes \,.
\]
The constant \(\ptr\) defines the size of a pointer. Any model of
the signature above will suffice; such a model might encode a sophisticated
layout algorithm with padding, for example.

To begin with, types are indexed by
bytes:\footnote{For brevity we will not regard issues of universe sizing, but this can
	be accomodated without issue.} $\Ty : \Bytes \to \Set$.
We have the following basic type and term formers:
\begin{align*}
	 & \univ_{\_} : \Bytes \to \Ty\ 0\qquad \Tm\ \univ_b = \Ty\ b                                      \\
	 & \square : \Ty\ b \to \Ty\ \ptr\qquad \syn{box} : \Tm\ \square A \simeq \Tm\ A : \syn{unbox} \,.
\end{align*}
The universe \(\univ_b\) describes types whose inhabitants take up \(b\) bytes, with a Grothendiek-style
identification $\Tm\ \univ_b = \Ty\ b$. The \(\square\) type former takes sized types
to types which \emph{box} their contents. In other words, for a type $A$ of some
size $a$, an inhabitant of data of \(\square A\) will be stored on the heap
behind a pointer indirection. On the other hand, an inhabitant of \(A\) will be
stored \emph{inline} on the stack, since it is known that \(A\) takes up exactly
\(a\) bytes. Codes for types of any kind take up no space at runtime because
they are erased. Additionally, we have boxing and unboxing operators for types
of a known size. Since we present this as a second-order theory, we can mechanically derive
its first-order presentation \cite{Kaposi2024-db}, with explicit contexts. There, contexts $\Gamma$
record the size of each type, such that $\textrm{b}( \Gamma) : \Bytes$ can be defined as
the sum of the sizes of its types. The action of substitutions on types does not
vary their sizes: $-[-] : \Ty\ \Gamma\ b \to \Sub\ \Delta\ \Gamma \to \Ty\
	\Delta\ b$.

\paragraph{Functions and unboxed pairs}\label{function-types}

This setup can be augmented with $\Pi$ and $\Sigma$ types, where the dependency
is \emph{uniform} with respect to layout:
\begin{align*}
	 & \Pi : (A : \Ty\ a) \to (\Tm\ A \to \Ty\ b) \to \Ty\ \ptr           \\
	 & \Sigma : (A : \Ty\ a) \to (\Tm\ A \to \Ty\ b) \to \Ty\ (a + b) \,.
\end{align*}
For functions, we store a pointer to an allocation containing both code and data.
Alternatively, we could separate the two by sizing functions as $\ptr + \ptr$.
Conversely, pairs are stored inline; their size is the sum of the sizes of their
components. The term formers remain unchanged.

It could be desirable to have a function type with \emph{unboxed} captures,
which might look like
\[
	\Pi_k : (A : \Ty\ a) \to (\Tm\ A \to \Ty\ b) \to (\ptr + k)  \,,
\]
annotated with the size of its captures $k$. This is not
expressible as a second-order construct because its term former must know about
captured variables:
$\lambda : (\rho : \syn{Sub}\ \Gamma\ \Delta) \to \Tm\ (\Delta \rhd A)\ B \to \Tm\ \Gamma\ (\Pi_{\textrm{b}(\Delta)}\ A\ B)[\rho]$.
This also means it is not immediately compatible with 2LTT. We leave this
as future work, which would likely involve a modality for closed object terms.

% In practice this substitution can be inferred from the surface program.

\paragraph{First-class byte values with staging}\label{layouts-staging}

This type theory can be embedded as an object language $\mathbb{O}$ of a 2LTT.
On the meta level, we have a type former $\mathbb{B} : \Ty_1$ of byte
values, and term formers that mirror $\Bytes$.
In an empty context, in the first-order formulation, we get an
evaluation function $\syn{ev} : \Tm_1\ \bullet\ \mathbb{B} \to \Bytes$.
Adding $\Pi$ types to the meta language
allows abstraction over byte values. Moreover, the meta level has a type former
$\Uparrow_b : \Ty_0\ b \to \Ty_1$ for embedding $(B : \Tm_1\ \mathbb{B})$-sized types from
the object fragment. If the final program is of the form $p :
	\Tm_1\ \bullet\ (\Uparrow_k A)$, after staging we get an object term of size $\syn{ev}\ k$.

% \paragraph{Padding type and unit}\label{padding-type-and-unit}

% Sometimes we want to store some extra bytes to pad a smaller type in
% order to reach a desired size. For this reason we add an extra type
% former \[
% \syn{Pad} : (b : \Bytes) \to \Ty\ \Gamma\ b \qquad \syn{pad} : \Tm\ \Gamma\ (\syn{Pad}\ b) \qquad
% \syn{pad-$\eta$} : (t : \Tm\ \Gamma\ (\syn{Pad}\ b)) \to t = \syn{pad}
% \] which is a generalisation of the unit type that takes up \(b\) bytes
% in memory. We can then define \(\mathbb{1} := \syn{Pad}\ 0\) and
% \(\syn{tt} := \syn{pad}\).

\paragraph{Example: $\syn{Maybe}$ as a tagged union}\label{maybe-as-a-tagged-union}

Let's take a look at how to define the \(\syn{Maybe}\) type internally in
such a way that its data is stored contiguously as a tagged union without indirections.\footnote{This
	is similar to the approach of languages such as Rust \cite{rust-option}.}.
We assume access to a type $\syn{Pad}\ b : \univ_b$ which is the unit
type that takes up $b$ bytes, with sole constructor $\syn{pad}$ akin to
$\syn{tt}$, and $\syn{Bool} : \univ_1$ which takes up a single byte:
\[
	\begin{aligned}
		 & \syn{Maybe} : (T : \univ_b) \to \univ_{1 + b}                                                                            \\
		 & \syn{Maybe}\ T = (x : \syn{Bool}) \times \syn{if}\ x\ \syn{then}\ T\ \syn{else}\ \syn{Pad}\ b                            \\[1em]
		 & \begin{alignedat}{2}
			    & \syn{nothing} : \{T : \univ_b\} \to \syn{Maybe}\ T  \qquad &  & \syn{just} : \{T : \univ_b\} \to T \to \syn{Maybe}\ T \\
			    & \syn{nothing} = (\syn{false}, \syn{pad})                   &  & \syn{just} = \lambda\ t.\  (\syn{true}, t)
		   \end{alignedat}
	\end{aligned}
\]

\paragraph{Computational irrelevance and runtime-sized data}

Annotating object-level types with bytes provides a convenient way to handle computational
irrelevance without further modifying the structure of contexts. This is possible through
a monadic modality
\[
	| - | : \Ty\ b \to \Ty\ 0 \qquad \parallel - \parallel\ : \Tm\ A \to \Tm\ | A |
\]
which is idempotent by $(A : \Ty\ 0) \to | A | = A$, extending to all zero-sized types.
It also has an appropriate eliminator form.
With this we can
reproduce, for example, quantitative type theory instantiated with the $\{0,\omega\}$ semiring
\cite{Atkey2018-pj}. This means that we can now use object-level types which are
entirely erased: $\syn{reverse} : \{n : | \syn{Nat} |\} \to \syn{Vect}\ T\ n \to \syn{Vect}\ T\ n$.

Additionally, we often want to handle data whose size is \emph{not} known at
compile-time, but is known at runtime; most commonly, heap-backed arrays, but
also other dynamically-sized flat data structures. This is achievable by
indexing the universe $\univ$ by partially-static \cite{Yallop2018-zw} byte
values. Object-level types $\Ty\ b$ are now identified only with
$\univ_{\syn{sta}\;b}$ where $\syn{sta} : \Tm_1\ \mathbb{B} \to \Tm_1\
	\mathbb{B}^{\syn{PS}}$. We can then add appropriate type formers to the theory
for the construction of runtime-sized data such as pairs. Their inhabitants
cannot directly be stored on the stack, but they can be constructed and
manipulated on the heap. To do this, boxing is relaxed to allow runtime-sized
data, and we must have a type for `generating' unsized data. We plan on presenting
examples of this in our presentation.

% A basic example is
% the construction of arrays as iterated runtime-sized pairs, which can be stack
% or heap allocated depending on if their size is known at compile-time.
% \begin{align*}
% 	 & \syn{Array} : (n : \syn{Nat}) \to (T : \univ_{\syn{sta}\; b}) \to \univ_{n \times \syn{sta}\; b} \\
% 	 & \syn{Array}\ \syn{zero}\ T = \syn{Unit}                                                          \\
% 	 & \syn{Array}\ (\syn{succ}\ n)\ T = T \times \syn{Array}\ n\ T                                     \\[1em]
% \end{align*}

% We also have an eliminator for irrelevant types
% \[
% 	\syn{elim-}|| : (P : |A| \to U_0) \to ((a : A) \to P \parallel a \parallel) \to (a : |A|) \to P\ a  \,, \\
% \]
% which says we can assume any irrelevant data is relevant, as long as we produce
% something zero-sized in the end. It comes with the computation rule
% $\syn{elim-}||\ P\ f\ (\parallel a \parallel) = f\ a$ similar to the usual
% eliminators for modal types \cite{Gratzer2020-hi}.
% In practice, invocations of $\parallel - \parallel$ can be inferred, and
% $\syn{elim-}||$ can be presented as a `let' expression.

\paragraph{Formalisation, semantics and implementation}

We have formalised most parts of the sketched system by a shallow embedding in
Agda, including the irrelevance modality. We have also formulated a semantics in
terms of an untyped lambda calculus which is nevertheless \emph{sized} just like
the system we presented. Crucially, the sizes of all constructs in this target language
must be \emph{non-zero}, which forces us to translate away all zero-sized types. This
justifies the irrelevance modality as well as the erased codes for types. We are
currently working on a proof-of-concept implementation that targets LLVM.

% \paragraph{Example: Arrays}\label{arrays}

% We can extend the language with flat arrays of a statically known size $n : \syn{Nat}$ by
% $\syn{Array}\ n : \Ty\ \Gamma\ b \to \Ty\ \Gamma\ (n \times b)$, as well
% as of a runtime size $r : \Tm\ \Gamma\ \mathbb{N}$ by $\syn{DynArray}\ r : \Ty\ \Gamma\ b \to \Tm\ \Gamma\ \univ$
% whose inhabitants can only be accessed under a box. For example,
% \[
% 	\Sigma\ (n : \mathbb{N})\ (\El_\square\ (\syn{DynArray}\ n\ (\syn{Array}\ 2\ (\Pi_k\ A\ B))))
% \]
% is the type of dynamically-sized arrays of pairs of closures from $A$ to $B$ of capture size $k$.
